{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzRc5xOScMUU"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dropout\n",
        "class_names = [ 'Triche','Non_Triche']\n",
        "# Charger les images et les labels à partir du répertoire\n",
        "images = []\n",
        "labels = []\n",
        "data_dir='DATA_BAW'\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for image_file in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, (200,200))  # Redimensionner l'image à la taille d'entrée du modèle\n",
        "            images.append(image)\n",
        "            labels.append(class_names.index(class_name))\n",
        "\n",
        "# Convertir les listes en tableaux numpy\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normaliser les valeurs des pixels entre 0 et 1\n",
        "images = images / 255.0\n",
        "\n",
        "# Convertir les labels en vecteurs catégoriques\n",
        "labels = to_categorical(labels, len(class_names))\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement, de validation et de test\n",
        "\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images,train_labels, test_size=0.2, random_state=42)\n",
        "# Augmentation de données\n",
        "datagen = ImageDataGenerator(rotation_range=0, zoom_range=0.3, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/https://drive.google.com/drive/folders/10GsZXRSeb4V8g1ThD5lLAufuJyINYTEf?fbclid=IwAR2eZ3JpkD8vcCJ_SCsysrD5tyD4LvIdW74TOKdFqZeHJZ8kBikixZBDIqQ')"
      ],
      "metadata": {
        "id": "Nt1s8F3j2-Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqd8uNjdcMUZ"
      },
      "outputs": [],
      "source": [
        "# Création du modèle CNN\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(200,200, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(len(class_names), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ctRHIuucMUa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(train_images, train_labels, epochs=6, validation_data=(val_images, val_labels))\n",
        "# Évaluation du modèle sur l'ensemble de test\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmjw-1HScMUb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olsunfzicMUc"
      },
      "outputs": [],
      "source": [
        "#model.save('model.h5')\n",
        "class_names = [ 'Triche','Non_Triche']\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Chemin vers le répertoire contenant les images de test sur Google Drive\n",
        "test_dir = '/content/output'\n",
        "\n",
        "# Liste des chemins d'accès des images de test\n",
        "image_paths = [\n",
        "    os.path.join( \"Suspect\", \"20231031_135659.jpg\"),\n",
        "    os.path.join( \"Suspect\", \"20231031_140016.jpg\"),\n",
        "    os.path.join( \"Suspect\", \"20231031_141929.jpg\"),\n",
        "    os.path.join( \"Suspect\", \"20231031_142444.jpg\"),\n",
        "    os.path.join(\"validation\", \"result1.jpg\"),\n",
        "    os.path.join(\"validation\", \"result18.jpg\"),\n",
        "    os.path.join(\"validation\", \"result24.jpg\"),\n",
        "    os.path.join(\"validation\", \"result20.jpg\"),\n",
        "    os.path.join(\"validation\", \"result23.jpg\"),\n",
        "    os.path.join(\"validation\", \"result5.jpg\"),\n",
        "    os.path.join(\"validation\", \"result16.jpg\"),\n",
        "    os.path.join(\"validation\", \"result17.jpg\"),\n",
        "    os.path.join(\"validation\", \"result1.jpg\"),\n",
        "    os.path.join(\"validation\", \"result14.jpg\"),\n",
        "    os.path.join(\"validation\", \"result13.jpg\"),\n",
        "    os.path.join(\"validation\", \"result26.jpg\"),\n",
        "    os.path.join(\"validation\", \"result2.jpg\"),\n",
        "    os.path.join(\"validation\", \"result19.jpg\"),\n",
        "    os.path.join(\"validation\", \"Capture2.jpg\"),\n",
        "    os.path.join(\"validation\", \"Capture3.jpg\"),\n",
        "\n",
        "]\n",
        "\n",
        "for test_image_path in image_paths:\n",
        "    # Charger l'image de test\n",
        "    test_image = cv2.imread(test_image_path)\n",
        "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
        "    # Vérifier si l'image a été chargée avec succès\n",
        "    if test_image is not None:\n",
        "        plt.imshow(test_image, cmap='gray')\n",
        "        plt.show()\n",
        "        test_image = cv2.resize(test_image, (200, 200))\n",
        "        # Redimensionner l'image à la taille d'entrée du modèle\n",
        "        # Normaliser les valeurs des pixels entre 0 et 1\n",
        "        test_image = test_image / 255.0\n",
        "        # Ajouter une dimension supplémentaire pour représenter le lot\n",
        "        test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "        # Prédire la classe de l'image de test\n",
        "        predictions = model.predict(test_image)\n",
        "        probabilities = tf.nn.softmax(predictions)\n",
        "\n",
        "        # Obtenir l'indice de classe prédit\n",
        "        predicted_class_index = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "\n",
        "        # Obtenir le nom de classe prédit\n",
        "        predicted_class = class_names[predicted_class_index]\n",
        "\n",
        "        # Afficher les résultats\n",
        "        print(\"Image:\", test_image_path)\n",
        "        print(\"Classe prédite:\", predicted_class)\n",
        "        print(\"Probabilités:\", probabilities.numpy()[0])\n",
        "        print()\n",
        "    else:\n",
        "        print(\"Échec du chargement de l'image :\", test_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in9yUHwRcMUc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from PIL import Image\n",
        "model1 = YOLO('yolov8n-pose.pt')\n",
        "video_path = 'Cas triche (exchange paper).mp4'\n",
        "i = 0\n",
        "counter = 0\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  counter +=1\n",
        "  if counter % 30 == 0:\n",
        "    results1 = model1.predict(frame, conf=0.5, classes=[0])\n",
        "    frame_color=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    #frame=Image.fromarray(frame)\n",
        "    for r in results1:\n",
        "        im_array = r.plot()\n",
        "        im = Image.fromarray(im_array[..., ::-1])\n",
        "        for b in r.boxes.xyxy:\n",
        "          b=np.array(b)\n",
        "         # x=b[0]\n",
        "         # y=b[1]\n",
        "          #z=b[2]\n",
        "          #r=b[3]\n",
        "          x, y, z, r = map(int, b)\n",
        "          cropped_image = frame[y:r, x:z]\n",
        "          #cropped_image = frame.crop((x,y,z,r))\n",
        "          cropped_image_saved=Image.fromarray(cropped_image)\n",
        "          output_path = os.path.join('test', f'++result{i}++.jpg')\n",
        "          cropped_image_saved.save(output_path)\n",
        "          #cropped_image_new = cv2.imread(output_path)\n",
        "          cropped_image = cv2.resize(cropped_image, (200, 200))\n",
        "          normalized_cropped_image =cropped_image / 255.0\n",
        "          normalized_cropped_image = np.expand_dims(normalized_cropped_image, axis=0)\n",
        "          predictions = model.predict(normalized_cropped_image)\n",
        "          probabilities = tf.nn.softmax(predictions)\n",
        "          predicted_class_index = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "          predicted_class = class_names[predicted_class_index]\n",
        "          print(predicted_class)\n",
        "          if (predicted_class=='Triche'):\n",
        "            plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.show()\n",
        "            plt.imshow(cv2.cvtColor(frame_color, cv2.COLOR_BGR2RGB))\n",
        "            plt.show()\n",
        "            print(i)\n",
        "          i=i+1\n",
        "    if cv2.waitKey(25) & 0xFF == ord('e'):\n",
        "      break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g89QFcKocMUd"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import math\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, 640)\n",
        "cap.set(4, 480)\n",
        "model_yolo = YOLO('yolov8n-pose.pt')\n",
        "counter=0\n",
        "i=0\n",
        "while True:\n",
        "\n",
        "    success, img = cap.read()\n",
        "    results = model_yolo(img, stream=True)\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0]\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
        "    cv2.imshow('Examen', img)\n",
        "    if counter % 10 == 0:\n",
        "        results = model_yolo(img, stream=True)\n",
        "        img_color=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_NB=cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
        "        for r in results:\n",
        "           im_array = r.plot()\n",
        "           im = Image.fromarray(im_array[..., ::-1])\n",
        "           for b in r.boxes.xyxy:\n",
        "             b=np.array(b)\n",
        "             x, y, z, r = map(int, b)\n",
        "             cropped_image = img_NB[y:r, x:z]\n",
        "             #cropped_image_saved=Image.fromarray(cropped_image)\n",
        "             #output_path = os.path.join('test', f'++result{i}++.jpg')\n",
        "             #cropped_image_saved.save(output_path)\n",
        "             cropped_image = cv2.resize(cropped_image, (200, 200))\n",
        "             normalized_cropped_image =cropped_image / 255.0\n",
        "             normalized_cropped_image = np.expand_dims(normalized_cropped_image, axis=0)\n",
        "             predictions = model.predict(normalized_cropped_image)\n",
        "             probabilities = tf.nn.softmax(predictions)\n",
        "             predicted_class_index = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "             predicted_class = class_names[predicted_class_index]\n",
        "             print(predicted_class)\n",
        "             if (predicted_class=='Triche'):\n",
        "                cropped_image_saved = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
        "                dossier=os.path.join('Live', f'frame{i}.jpg')\n",
        "                if not os.path.exists(dossier):\n",
        "                        os.makedirs(dossier)\n",
        "                output_path_pil = os.path.join(dossier, f'result_pil_{counter}_{i}.jpg')\n",
        "                cropped_image_saved.save(output_path_pil)\n",
        "                cropped_image_saved.close()\n",
        "                plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_GRAY2RGB))\n",
        "                plt.show()\n",
        "                img_saved = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "                output_path_pil = os.path.join(dossier, f'result_{counter}_{i}.jpg')\n",
        "                img_saved.save(output_path_pil)\n",
        "                cropped_image_saved.close()\n",
        "                plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    i=i+1\n",
        "    counter=counter+1\n",
        "    if cv2.waitKey(1) == ord('e'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}